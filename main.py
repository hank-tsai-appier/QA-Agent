import os
import asyncio
import dotenv

from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client
from langchain_mcp_adapters.tools import load_mcp_tools
from langchain_google_genai import ChatGoogleGenerativeAI
from langgraph.graph import StateGraph, END

from typing import Any, List, Dict, Optional, Union
from pydantic import BaseModel, Field

import json
import uuid
from pathlib import Path
from src.utils.json_fommatter import JsonFormatter
from src.prompt_loader import load_prompts



dotenv.load_dotenv()

LLM = ChatGoogleGenerativeAI(model="gemini-2.5-flash", api_key=os.getenv("GOOGLE_API_KEY"))

SERVER_PARAM = StdioServerParameters(
    command="npx",
    args=["-y", "chrome-devtools-mcp@latest", "--isolated"]
)

TODO_FILE_PATH = Path("todo")
TODO_FILE_PATH.mkdir(parents=True, exist_ok=True)
RESULT_OFFSET = -3

# Initialize prompt loader
PROMPT_LOADER = load_prompts()


class Todo(BaseModel):
    """
    Todo model for the todos list
    """
    id: int = Field(description="The id of the todo")
    type: str = Field(description="The type of the todo")
    description: str = Field(description="The description of the todo")
    status: str = Field(description="The status of the todo")


class AgentState(BaseModel):
    """
    AgentState defines the mutable state shared across the agent's workflow.
    """
    task_id: str = Field(
        default_factory=lambda: str(uuid.uuid4()), 
        description="A unique identifier for the agent task."
    )
    goal: Optional[str] = Field(
        default=None, 
        description="The main goal or instruction for the agent."
    )
    todos: List[Todo] = Field(
        default_factory=list,
        description="A list of todo items generated from the goal."
    )
    ui_todos: List[Todo] = Field(
        default_factory=list,
        description="A list of ui todos items generated from the goal."
    )
    current_todo_index: int = Field(
        default=0,
        description="The index of the current todo being executed."
    )
    current_plan: Optional[Union[str, dict]] = Field(
        default=None,
        description="The current plan output generated by the step planner LLM."
    )
    tool_name: Optional[str] = Field(
        default=None,
        description="The tool chosen to execute for the next step."
    )
    tool_input: Any = Field(
        default=None,
        description="The specific input or arguments for the selected tool."
    )
    result: List[Any] = Field(
        default_factory=list,
        description="The output or result from the tool execution."
    )
    error: Optional[str] = Field(
        default=None,
        description="Any error message encountered during planning or acting."
    )
    success: Optional[bool] = Field(
        default=None,
        description="Whether the last action was successful."
    )
    step: int = Field(
        default=0,
        description="The current step number in the planning-execution loop."
    )
    history: List[Dict[str, Any]] = Field(
        default_factory=list,
        description="A list of dicts with previous steps taken, including past plans, results, etc."
    )

async def todo_planner(state: AgentState):
    """
    Analyze the goal and create a structured list of todos.
    Each todo represents a discrete step needed to achieve the goal.
    """
    global PROMPT_LOADER
    print("=" * 60)
    print("TODO_PLANNER: Creating task breakdown...")

    todo_prompt = PROMPT_LOADER.format_prompt(
        "todo_planner",
        goal=state.goal
    )

    res = await LLM.ainvoke(todo_prompt)

    try:
        content = JsonFormatter.remove_markdown_markers(res.content)

        # load the todos
        todo_result = json.loads(content)

        # parse the todos into Todo model
        # include api todos and ui todos
        state.todos = [Todo(**todo) for todo in todo_result.get("todos", [])]

        print([f"{todo}\n" for todo in state.todos])
        
        # parse the ui todos into Todo model
        state.ui_todos = [Todo(**todo) for todo in todo_result.get("todos", []) if todo.get("type") == "ui"]
    
        print(f"\n✅ Created {len(state.todos)} todos:")

        # write content to todo.md
        # this is for the final automation script generation
        with open(TODO_FILE_PATH / f"todo_{state.task_id}.md", "w", encoding="utf-8") as f:
            for todo in state.todos:
                line = f"[{todo.id}] ({todo.type}) {todo.description}\n"
                f.write(line)

        # write content to ui_todo.md
        # this is for the ui step planner and executor
        with open(TODO_FILE_PATH / f"ui_todo_{state.task_id}.md", "w", encoding="utf-8") as f:
            for todo in state.ui_todos:
                line = f"[{todo.id}] ({todo.type}) {todo.description}\n"
                f.write(line)

        state.error = None
        state.success = True
    except Exception as e:
        state.error = f"Failed to parse todos: {e}"
        state.success = False
        print(f"❌ Error creating todos: {e}")
    
    return state

async def step_planner(state: AgentState):
    """
    Plan the next step based on the current ui todo and the last result and error
    Output the plan in JSON format
    """
    # get tools info
    global PROMPT_LOADER
    print("\n============= PLANNING_NEXT_STEP =============")
    
    # Get current todo if available
    current_ui_todo = None
    if state.ui_todos and state.current_todo_index < len(state.ui_todos):
        current_ui_todo = state.ui_todos[state.current_todo_index]


    # print current ui todo
    print(f"Current UI Todo: {current_ui_todo}\n")

    plan_prompt = PROMPT_LOADER.format_prompt(
        "step_planner",
        current_ui_todo=current_ui_todo,
        last_result=state.result[RESULT_OFFSET:],
        suggestion=state.error,
        tools_info=""
    )

    print(f"Plan prompt: {plan_prompt}")

    res = await LLM.ainvoke(plan_prompt)


    # Parse the plan content (expect user to handle JSON, simple eval fallback)
    try:
        # Remove ```json and ``` markers from res.content if present (e.g., LLM returns Markdown-formatted JSON)
        plan_str = JsonFormatter.remove_markdown_markers(res.content)
        plan_result = json.loads(plan_str)
        state.current_plan = plan_result
        
        print(f"Plan Reason: {plan_result.get('reason')}\n")
        print(f"Plan confidence: {plan_result.get('confidence')}\n")
    except Exception:
        try:
            plan_result = eval(res.content, {}, {}) # fallback for quick prototyping
        except Exception as e:
            state.error = f"Invalid plan parse: {e}"
            state.success = False
            return state

    state.tool_name = plan_result.get("tool_name")
    state.tool_input = plan_result.get("tool_input")

    return state

async def executor(state: AgentState):
    global SESSION
    print("\n============= EXECUTING_STEP =============")
    print(f"Execute: {state.current_plan}")

    try:
        # async MCP tool execution
        # Get session/tools from outer scope via context hack (closure or global singletons for simplicity)
        tool_name = state.tool_name
        tool_input = state.tool_input

        
        if not tool:
            state.error = f"Tool '{tool_name}' not found"
            state.result.append(None)
        else:
            output = await tool.ainvoke(tool_input, session=SESSION)
            state.result.append(output)
            state.error = None
    except Exception as e:
        state.error = str(e)
        state.result.append(None)

    # print current tool and result
    print(f"Result: {state.result[-1]}\n")
    print(f"Error: {state.error}\n")

    return state

async def judge(state: AgentState):
    """
    Judge the result of the current step and decide if the current step is successful
    Change the todo.md file based on the result and update the current todo index and todo.status
    """
    global PROMPT_LOADER

    # skip judging if the tool is take_snapshot
    if state.tool_name == "take_snapshot":
        return state
    
    print("\n============= JUDGING =============")

    # Get current todo for context
    current_ui_todo = None
    if state.ui_todos and state.current_todo_index < len(state.ui_todos):
        current_ui_todo = state.ui_todos[state.current_todo_index]

    judge_prompt = PROMPT_LOADER.format_prompt(
        "judge",
        goal=state.goal,
        current_ui_todo=current_ui_todo,
        result=state.result[RESULT_OFFSET:],
        error=state.error
    )
    
    res = await LLM.ainvoke(judge_prompt)
    try:
        content = JsonFormatter.remove_markdown_markers(res.content)
        verdict = json.loads(content)
        state.success = verdict.get("success", False)
        state.error = verdict.get("reason") if not state.success else None

        # print current todo and judge verdict
        print(f"Current Todo: {current_ui_todo}\n")
        print(f"Judge verdict: {verdict}\n")

        # Update current todo index if a todo was completed
        todo_completed = verdict.get("todo_completed", False)
        if todo_completed and state.todos and state.current_todo_index < len(state.todos):
            state.todos[state.current_todo_index].status = "completed"
            state.current_todo_index += 1
            print(f"✅ Todo completed! Progress: {state.current_todo_index}/{len(state.todos)}\n")


    except Exception as e:
        state.success = False
        state.error = f"Judge parse failed: {e}"
        print(f"❌ Judge parse failed: {e}")

    return state

async def write_automation_script(state: AgentState):
    pass


def decide_next(state: AgentState):
    return END if state.success else "step_planner"

async def main():
    global SESSION, LLM
    async with stdio_client(SERVER_PARAM) as (read, write):
        async with ClientSession(read, write) as session:
            SESSION = session
            await session.initialize()
            tools = await load_mcp_tools(session)
            LLM = LLM.bind_tools(tools)

            workflow = StateGraph(AgentState)

            # nodes
            workflow.add_node("todo_planner", todo_planner)
            workflow.add_node("step_planner", step_planner)
            workflow.add_node("executor", executor)
            workflow.add_node("judge", judge)
            
            # edges
            workflow.add_edge("todo_planner", "step_planner")
            workflow.add_edge("step_planner", "executor")
            workflow.add_edge("executor", "judge")
            workflow.add_conditional_edges("judge", decide_next, {"step_planner": "step_planner", END: END})

            # entry point
            workflow.set_entry_point("todo_planner")

            # compile
            graph = workflow.compile()

            # draw graph
            print(graph.get_graph().draw_ascii())


            # invoke graph
            initial_goal = """
1. 用track/ce api打資料到nxl6ldktnc, 以下是api的指令，請幫我使用GET方法打資料https://www.woopra.com/track/ce?project=aiquasdk.prd.com&event=update/insert_any_object&cv_user_id=u0091&cv_name=hank&cv_phone=U53297d8d527739ce4e80cbe200a55478&cv_email=hank@email.abc.com
2. 用logger.info設定印出回傳的status code
3. 打開https://airis.appier.com進行登入，帳號是qa.test@appier.com，密碼是aaAA1234
4. go_to_url: https://airis.appier.com/project/aiquasdk.prd.com/profiles/nxl6ldktnc
5. 點擊畫面右側的有三個點的button，會跳出一個下拉選單
6. 點擊Sync
7. 在filter輸入Salesforce
8. 點擊sync to Salesforce
9. 點擊Object type的下拉選單並在Filter輸入Contact
10. 點擊Contact並Wait_for_networkidle
11. 接下來點擊Add Salesforce Field三次，會有三個Map Field需要填寫
12. 點選Salesforce的下拉選單，在Filter中輸入Last Name，點擊選單中的Last Name
13. 接下來點擊AIRIS field右側的**(X)**，點擊後會出現下拉選單，點擊Name，請注意不是delete button
14. 點選Salesfoce的下拉選單，在Filter中輸入Mobile Phone，點擊選單中的Mobile Phone
15. 接下來點擊AIRIS field右側的**(X)**，點擊後會出現下拉選單，點擊phone
16. 點選Salesfoce的下拉選單，在Filter中輸入Email，點擊選單中的Email
17. 接下來點擊AIRIS field右側的**(X)**，點擊後會出現下拉選單，點擊email
18. 按下點擊export
19. Wait for import complete的訊息出現
20. 使用/rest/e.10/profiles抓取profile
https://www.woopra.com/rest/3.10/profiles?report_id=nxl6ldktnc&project=aiquasdk.prd.com&force=true&update_mapping=true
21. 使用api抓取salesforce Contact 內容
22. 進行比對


你可以先分辨哪些是UI操作哪些是其他操作，我希望你可以專注在UI上面，其他操作你可以在最後打api來獲取資訊並寫在程式中

請幫我使用chrome-devtools-mcp執行UI操作相關的內容，並在執行後幫我寫一個playwright code，用於執行這個test plan的automation

            """
            state = AgentState(goal=initial_goal)
            print(f"\n============== AGENT START ==============")
            print(f"Agent Task ID: {state.task_id}")
            result_state = await graph.ainvoke(state, config={"recursion_limit": 100})

            # print result
            print("✅ Final:", result_state)

if __name__ == "__main__":
    asyncio.run(main())
